"use strict";(self.webpackChunkneuraltrust_docs=self.webpackChunkneuraltrust_docs||[]).push([[8430],{5612:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>r,contentTitle:()=>l,default:()=>d,frontMatter:()=>o,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"red-teaming/key-concepts/evaluation-sets","title":"Evaluation Sets","description":"Evaluation Sets are a core feature of the NeuralTrust platform that allow you to systematically test and evaluate AI models. They provide a structured way to organize and automate collections of tests to assess model performance, safety, and compliance.","source":"@site/docs/red-teaming/key-concepts/evaluation-sets.md","sourceDirName":"red-teaming/key-concepts","slug":"/red-teaming/key-concepts/evaluation-sets","permalink":"/red-teaming/key-concepts/evaluation-sets","draft":false,"unlisted":false,"editUrl":"https://github.com/NeuralTrust/neuraltrust/blob/main/docs/red-teaming/key-concepts/evaluation-sets.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Key Components","permalink":"/red-teaming/key-concepts/overview"},"next":{"title":"Test Sets","permalink":"/red-teaming/key-concepts/testsets"}}');var s=n(4848),i=n(8453);const o={sidebar_position:2},l="Evaluation Sets",r={},c=[{value:"How to create an Evaluation Set manually?",id:"how-to-create-an-evaluation-set-manually",level:2}];function u(e){const t={a:"a",h1:"h1",h2:"h2",header:"header",img:"img",li:"li",ol:"ol",p:"p",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.header,{children:(0,s.jsx)(t.h1,{id:"evaluation-sets",children:"Evaluation Sets"})}),"\n",(0,s.jsx)(t.p,{children:"Evaluation Sets are a core feature of the NeuralTrust platform that allow you to systematically test and evaluate AI models. They provide a structured way to organize and automate collections of tests to assess model performance, safety, and compliance."}),"\n",(0,s.jsx)(t.p,{children:"With Evaluation Sets, you can:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Create reusable test collections for consistent model evaluation"}),"\n",(0,s.jsx)(t.li,{children:"Schedule automated evaluations to run on a regular basis (daily, weekly, etc.)"}),"\n",(0,s.jsx)(t.li,{children:"Track model performance and safety metrics over time"}),"\n",(0,s.jsx)(t.li,{children:"Add custom metadata to organize and categorize your evaluation sets"}),"\n",(0,s.jsx)(t.li,{children:"Run evaluations on-demand or automatically through the API"}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"Evaluation Sets are particularly useful for:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Quality assurance testing of AI models"}),"\n",(0,s.jsx)(t.li,{children:"Continuous monitoring of model behavior"}),"\n",(0,s.jsx)(t.li,{children:"Compliance verification and documentation"}),"\n",(0,s.jsx)(t.li,{children:"Regression testing after model updates"}),"\n"]}),"\n",(0,s.jsxs)(t.p,{children:["For more information, see the ",(0,s.jsx)(t.a,{href:"/sdks/python-sdk/api-reference/evaluation-set-client",children:"Evaluation Sets API Reference"}),"."]}),"\n",(0,s.jsx)(t.h2,{id:"how-to-create-an-evaluation-set-manually",children:"How to create an Evaluation Set manually?"}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"Evaluation Sets",src:n(1759).A+"",width:"1766",height:"1444"})}),"\n",(0,s.jsx)(t.p,{children:"You can create and manage Evaluation Sets directly through the NeuralTrust web interface without needing to use the SDK:"}),"\n",(0,s.jsxs)(t.ol,{children:["\n",(0,s.jsx)(t.li,{children:'Navigate to the "Evaluation Sets" section in the NeuralTrust dashboard'}),"\n",(0,s.jsx)(t.li,{children:'Click the "Create New Evaluation Set" button'}),"\n",(0,s.jsxs)(t.li,{children:["Fill in the basic information:","\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Name: Give your evaluation set a descriptive name"}),"\n",(0,s.jsx)(t.li,{children:"Description: Add details about the purpose and scope"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"Once created, you can:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Add test cases directly through the web interface"}),"\n",(0,s.jsx)(t.li,{children:"Edit existing test cases"}),"\n",(0,s.jsx)(t.li,{children:"Run evaluations with a single click"}),"\n",(0,s.jsx)(t.li,{children:"View detailed results and analytics"}),"\n",(0,s.jsx)(t.li,{children:"Schedule automated runs"}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"The web interface provides an intuitive way to manage your evaluation sets while offering the same functionality as the SDK methods."})]})}function d(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(u,{...e})}):u(e)}},1759:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/images/evaluation-set-fbd4be191d604bcc627b45ca38b19ab7.png"},8453:(e,t,n)=>{n.d(t,{R:()=>o,x:()=>l});var a=n(6540);const s={},i=a.createContext(s);function o(e){const t=a.useContext(i);return a.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),a.createElement(i.Provider,{value:t},e.children)}}}]);