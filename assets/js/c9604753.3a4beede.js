"use strict";(self.webpackChunkneuraltrust_docs=self.webpackChunkneuraltrust_docs||[]).push([[7254],{1789:(e,t,s)=>{s.r(t),s.d(t,{assets:()=>c,contentTitle:()=>a,default:()=>u,frontMatter:()=>o,metadata:()=>n,toc:()=>l});const n=JSON.parse('{"id":"red-teaming/key-concepts/testsets","title":"Test Sets","description":"Test Sets are a fundamental component of the NeuralTrust platform that enable you to create and manage collections of test cases for AI model evaluation. Each test set contains multiple query-response pairs, where each pair consists of:","source":"@site/docs/red-teaming/key-concepts/testsets.md","sourceDirName":"red-teaming/key-concepts","slug":"/red-teaming/key-concepts/testsets","permalink":"/red-teaming/key-concepts/testsets","draft":false,"unlisted":false,"editUrl":"https://github.com/NeuralTrust/neuraltrust/blob/main/docs/red-teaming/key-concepts/testsets.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Evaluation Sets","permalink":"/red-teaming/key-concepts/evaluation-sets"},"next":{"title":"Knowledge Bases","permalink":"/red-teaming/key-concepts/knowledge-bases"}}');var r=s(4848),i=s(8453);const o={sidebar_position:3},a="Test Sets",c={},l=[];function d(e){const t={a:"a",h1:"h1",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.header,{children:(0,r.jsx)(t.h1,{id:"test-sets",children:"Test Sets"})}),"\n",(0,r.jsx)(t.p,{children:"Test Sets are a fundamental component of the NeuralTrust platform that enable you to create and manage collections of test cases for AI model evaluation. Each test set contains multiple query-response pairs, where each pair consists of:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Query"}),': The prompt or input that will be sent to the LLM (e.g., "What is the capital of France?")']}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Expected Response"}),': The correct or desired response that the LLM should provide (e.g., "The capital of France is Paris.")']}),"\n"]}),"\n",(0,r.jsx)(t.p,{children:"A single test set can contain dozens or hundreds of these query-response pairs, allowing you to thoroughly test your LLM across a wide range of scenarios. Test sets support both single-turn interactions and multi-turn conversations, enabling you to test:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"Simple question-answer pairs"}),"\n",(0,r.jsx)(t.li,{children:"Complex dialogue scenarios with context"}),"\n",(0,r.jsx)(t.li,{children:"Multi-turn conversations where previous interactions matter"}),"\n",(0,r.jsx)(t.li,{children:"Conversation memory and context retention"}),"\n",(0,r.jsx)(t.li,{children:"Chat history dependent responses"}),"\n"]}),"\n",(0,r.jsx)(t.p,{children:"These test sets work in conjunction with Evaluation Sets to provide comprehensive testing capabilities for your LLM applications."}),"\n",(0,r.jsx)(t.p,{children:"With Test Sets, you can:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"Create large collections of query-response pairs with specific testing objectives"}),"\n",(0,r.jsx)(t.li,{children:"Generate multiple test cases automatically from knowledge bases"}),"\n",(0,r.jsx)(t.li,{children:"Organize sets of tests by type (functional, security, compliance, etc.)"}),"\n",(0,r.jsx)(t.li,{children:"Reuse test cases across multiple evaluation sets"}),"\n",(0,r.jsx)(t.li,{children:"Track how well your LLM responses match the expected responses over time"}),"\n",(0,r.jsx)(t.li,{children:"Test conversation flows and multi-turn interactions"}),"\n"]}),"\n",(0,r.jsx)(t.p,{children:"Test Sets are particularly useful for:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"Systematic testing of model capabilities and accuracy across many scenarios"}),"\n",(0,r.jsx)(t.li,{children:"Security and vulnerability assessment through multiple adversarial prompts"}),"\n",(0,r.jsx)(t.li,{children:"Compliance verification with expected response patterns at scale"}),"\n",(0,r.jsx)(t.li,{children:"Performance benchmarking against a comprehensive set of known good responses"}),"\n",(0,r.jsx)(t.li,{children:"Regression testing to ensure model behavior remains consistent across updates"}),"\n",(0,r.jsx)(t.li,{children:"Validation of contextual understanding in conversations"}),"\n"]}),"\n",(0,r.jsxs)(t.p,{children:["For more information, see the ",(0,r.jsx)(t.a,{href:"/sdks/python-sdk/api-reference/testset-client",children:"Test Sets API Reference"}),"."]})]})}function u(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,t,s)=>{s.d(t,{R:()=>o,x:()=>a});var n=s(6540);const r={},i=n.createContext(r);function o(e){const t=n.useContext(i);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),n.createElement(i.Provider,{value:t},e.children)}}}]);