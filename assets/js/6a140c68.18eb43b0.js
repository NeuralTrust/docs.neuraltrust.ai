"use strict";(self.webpackChunkneuraltrust_docs=self.webpackChunkneuraltrust_docs||[]).push([[3702],{1068:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>r,default:()=>u,frontMatter:()=>i,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"red-teaming/key-concepts/overview","title":"Key Components","description":"NeuralTrust defines the following components to support the above use cases:","source":"@site/docs/red-teaming/key-concepts/overview.md","sourceDirName":"red-teaming/key-concepts","slug":"/red-teaming/key-concepts/overview","permalink":"/red-teaming/key-concepts/overview","draft":false,"unlisted":false,"editUrl":"https://github.com/NeuralTrust/neuraltrust/blob/main/docs/red-teaming/key-concepts/overview.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Key Concepts","permalink":"/category/key-concepts-1"},"next":{"title":"Evaluation Sets","permalink":"/red-teaming/key-concepts/evaluation-sets"}}');var o=n(4848),a=n(8453);const i={sidebar_position:1},r="Key Components",c={},d=[{value:"Evaluation Sets",id:"evaluation-sets",level:2},{value:"Test Sets",id:"test-sets",level:2},{value:"Knowledge Bases",id:"knowledge-bases",level:2}];function l(e){const t={a:"a",h1:"h1",h2:"h2",header:"header",img:"img",p:"p",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.header,{children:(0,o.jsx)(t.h1,{id:"key-components",children:"Key Components"})}),"\n",(0,o.jsx)(t.p,{children:"NeuralTrust defines the following components to support the above use cases:"}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:"Red Teaming Components",src:n(4936).A+""})}),"\n",(0,o.jsx)(t.h2,{id:"evaluation-sets",children:(0,o.jsx)(t.a,{href:"/red-teaming/key-concepts/evaluation-sets",children:"Evaluation Sets"})}),"\n",(0,o.jsx)(t.p,{children:"Set of a Test Sets, evaluation criteria, runs and results. Each evaluation set defines specific test scenarios, success metrics, and evaluation parameters needed to thoroughly assess model behavior. These sets can be customized for different testing objectives, from security validation to functional performance evaluation. Evaluation sets can be scheduled to run automatically at defined intervals, enabling continuous monitoring and assessment of model performance over time."}),"\n",(0,o.jsx)(t.h2,{id:"test-sets",children:(0,o.jsx)(t.a,{href:"/red-teaming/key-concepts/testsets",children:"Test Sets"})}),"\n",(0,o.jsx)(t.p,{children:"Set of prompts and expected model responses pairs used in testing. Defines a conversation or a single query-response pair from your LLM application."}),"\n",(0,o.jsx)(t.h2,{id:"knowledge-bases",children:(0,o.jsx)(t.a,{href:"/red-teaming/key-concepts/knowledge-bases",children:"Knowledge Bases"})}),"\n",(0,o.jsx)(t.p,{children:"Information source that provides the foundation for model testing and validation. These repositories contain verified reference data, domain expertise, testing patterns, and compliance requirements. Knowledge bases help ensure that evaluations are grounded in accurate information and align with industry standards and security policies."})]})}function u(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},4936:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/evaluation-sets-schema-1c172591eefcee73775da30c366dbad6.svg"},8453:(e,t,n)=>{n.d(t,{R:()=>i,x:()=>r});var s=n(6540);const o={},a=s.createContext(o);function i(e){const t=s.useContext(a);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:i(e.components),s.createElement(a.Provider,{value:t},e.children)}}}]);