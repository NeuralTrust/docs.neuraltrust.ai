"use strict";(self.webpackChunkneuraltrust_docs=self.webpackChunkneuraltrust_docs||[]).push([[7894],{7961:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>r,toc:()=>o});const r=JSON.parse('{"id":"observability/tracing","title":"Tracing","description":"Comprehensive tracing capabilities for monitoring and debugging your LLM applications.","source":"@site/docs/observability/tracing.md","sourceDirName":"observability","slug":"/observability/tracing","permalink":"/neuraltrust/observability/tracing","draft":false,"unlisted":false,"editUrl":"https://github.com/NeuralTrust/neuraltrust/blob/main/docs/observability/tracing.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Analytics","permalink":"/neuraltrust/observability/analytics"},"next":{"title":"Monitors","permalink":"/neuraltrust/observability/monitors"}}');var i=s(4848),t=s(8453);const a={sidebar_position:3},l="Tracing",c={},o=[{value:"Why Trace LLM Applications?",id:"why-trace-llm-applications",level:2},{value:"Overview",id:"overview",level:2},{value:"Basic Usage",id:"basic-usage",level:2},{value:"Event Types",id:"event-types",level:2},{value:"MESSAGE",id:"message",level:3},{value:"TOOL",id:"tool",level:3},{value:"GENERATION",id:"generation",level:3},{value:"AGENT",id:"agent",level:3},{value:"RETRIEVAL",id:"retrieval",level:3},{value:"SYSTEM",id:"system",level:3},{value:"FEEDBACK",id:"feedback",level:3},{value:"Advanced Tracing Features",id:"advanced-tracing-features",level:2},{value:"Nested Tracing",id:"nested-tracing",level:3},{value:"Key Benefits",id:"key-benefits",level:3},{value:"Best Practices",id:"best-practices",level:3}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"tracing",children:"Tracing"})}),"\n",(0,i.jsx)(n.p,{children:"Comprehensive tracing capabilities for monitoring and debugging your LLM applications."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Tracing",src:s(6242).A+"",width:"1110",height:"762"})}),"\n",(0,i.jsx)(n.h2,{id:"why-trace-llm-applications",children:"Why Trace LLM Applications?"}),"\n",(0,i.jsx)(n.p,{children:"LLM applications can be complex systems with many moving parts - from prompt construction and context retrieval to tool usage and response generation. When something goes wrong or behaves unexpectedly, it can be challenging to understand exactly what happened. Tracing provides:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Debugging Clarity"}),": See exactly how your LLM processed a request, what context it used, and how it arrived at its response"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Performance Insights"}),": Identify bottlenecks in your application, like slow API calls or expensive retrievals"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Quality Monitoring"}),": Track the quality of LLM outputs and user satisfaction over time"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Compliance & Auditing"}),": Maintain detailed records of all LLM interactions for compliance requirements"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Cost Optimization"}),": Understand which parts of your system are making the most LLM calls and optimize accordingly"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"The tracing system captures detailed information about your LLM application's behavior and performance. This includes:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Message flows"}),": Track the complete conversation flow between users and your LLM, including intermediate steps"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Tool usage"}),": Monitor when and how your LLM uses external tools, APIs, and function calls"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Agent interactions"}),": Record agent reasoning steps, decisions, and actions taken"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Data retrievals"}),": Track RAG operations, document fetches, and context augmentation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Response generations"}),": Capture prompt construction, LLM calls, and response processing"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"System events"}),": Log infrastructure events, errors, and runtime information"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Custom events"}),": Define and track application-specific events important to your use case"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"User feedback"}),": Collect explicit ratings, implicit signals, and interaction outcomes"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"basic-usage",children:"Basic Usage"}),"\n",(0,i.jsx)(n.p,{children:"Create a trace and add events:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Initialize a trace\ntrace = client.trace(\n    conversation_id="conv_123",\n    session_id="session_123"\n)\n\n# Add a message event\nmessage = trace.message("User: What\'s the weather?")\nmessage.end("Bot: It\'s sunny!")\n'})}),"\n",(0,i.jsx)(n.h2,{id:"event-types",children:"Event Types"}),"\n",(0,i.jsx)(n.p,{children:"Each event type serves a specific purpose in tracking your LLM application's behavior:"}),"\n",(0,i.jsx)(n.h3,{id:"message",children:"MESSAGE"}),"\n",(0,i.jsx)(n.p,{children:"Root-level conversation events that capture the main interaction flow. Use these to track the overall conversation structure."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'message = trace.message("User input")\nmessage.end("Bot response")\n'})}),"\n",(0,i.jsx)(n.h3,{id:"tool",children:"TOOL"}),"\n",(0,i.jsx)(n.p,{children:"Tracks external tool and API usage. Perfect for monitoring function calls, database queries, or any external service interactions."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'tool = message.tool("Calling weather API")\ntool.end("API response received")\n'})}),"\n",(0,i.jsx)(n.h3,{id:"generation",children:"GENERATION"}),"\n",(0,i.jsx)(n.p,{children:"Captures LLM prompt construction and response generation. Use this to monitor token usage, response quality, and generation parameters."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'generation = message.generation("Generating response")\ngeneration.end("Response generated")\n'})}),"\n",(0,i.jsx)(n.h3,{id:"agent",children:"AGENT"}),"\n",(0,i.jsx)(n.p,{children:"Records agent reasoning steps and decisions. Useful for understanding how your LLM agent processes tasks and makes choices."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'agent = message.agent("Planning next action")\nagent.end("Decided to search database")\n'})}),"\n",(0,i.jsx)(n.h3,{id:"retrieval",children:"RETRIEVAL"}),"\n",(0,i.jsx)(n.p,{children:"Monitors document retrievals and RAG operations. Tracks what context was fetched and how it was used."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'retrieval = message.retrieval("Searching knowledge base")\nretrieval.end("Found 3 relevant documents")\n'})}),"\n",(0,i.jsx)(n.h3,{id:"system",children:"SYSTEM"}),"\n",(0,i.jsx)(n.p,{children:"Captures infrastructure events and runtime information. Use for monitoring system health and performance."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'system = trace.system("Initializing cache")\nsystem.end("Cache warmed up")\n'})}),"\n",(0,i.jsx)(n.h3,{id:"feedback",children:"FEEDBACK"}),"\n",(0,i.jsx)(n.p,{children:"Records user feedback and interaction outcomes. Essential for quality monitoring and improvement."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'trace.feedback(\n    feedback_tag="THUMBS_UP",\n    feedback_text="User marked response as helpful"\n)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"advanced-tracing-features",children:"Advanced Tracing Features"}),"\n",(0,i.jsx)(n.h3,{id:"nested-tracing",children:"Nested Tracing"}),"\n",(0,i.jsx)(n.p,{children:"Nested tracing is the recommended way to track complex interactions in your LLM application. It creates a hierarchical structure that makes it easy to understand the relationship between different operations:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Initialize trace with basic context\ntrace = client.trace(\n    conversation_id="conv_123",\n    metadata=Metadata(environment="production"),\n    user=User(id="user_123")\n)\n\ntry:\n    # Start main conversation trace\n    message = trace.message("User: Tell me about neural networks")\n    \n    # Track document retrieval\n    retrieval = message.retrieval("Searching documentation")\n    retrieval.end("Found 2 relevant articles")\n    \n    # Track response generation\n    generation = message.generation("Creating explanation")\n    generation.end("Generated response about neural networks")\n    \n    # Complete the conversation\n    message.end("Bot: Neural networks are...")\n\nexcept Exception as e:\n    message.end(f"Error: {str(e)}")\n'})}),"\n",(0,i.jsx)(n.h3,{id:"key-benefits",children:"Key Benefits"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Hierarchical Organization"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Each trace can have child traces (retrieval \u2192 generation)"}),"\n",(0,i.jsx)(n.li,{children:"Automatically maintains parent-child relationships"}),"\n",(0,i.jsx)(n.li,{children:"Makes complex flows easy to understand and debug"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Rich Context"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Add metadata for environment, versions, and custom properties"}),"\n",(0,i.jsx)(n.li,{children:"Track user information and session data"}),"\n",(0,i.jsx)(n.li,{children:"Include business-specific properties"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Error Handling"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Proper trace completion even during errors"}),"\n",(0,i.jsx)(n.li,{children:"Capture full error context"}),"\n",(0,i.jsx)(n.li,{children:"Maintain trace hierarchy in error cases"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Monitor Performance"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Track timing of key operations"}),"\n",(0,i.jsx)(n.li,{children:"Add context about resource usage"}),"\n",(0,i.jsx)(n.li,{children:"Monitor rate limits and quotas"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"best-practices",children:"Best Practices"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Structure Your Traces"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Start with a high-level message trace"}),"\n",(0,i.jsx)(n.li,{children:"Add child traces for major operations"}),"\n",(0,i.jsx)(n.li,{children:"Keep the hierarchy shallow (2-3 levels max)"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Add Meaningful Context"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Use descriptive trace names"}),"\n",(0,i.jsx)(n.li,{children:"Include relevant metadata"}),"\n",(0,i.jsx)(n.li,{children:"Track user and session information"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Handle Errors Properly"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Use try/except blocks"}),"\n",(0,i.jsx)(n.li,{children:"End traces in finally blocks"}),"\n",(0,i.jsx)(n.li,{children:"Include error details in trace output"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Monitor Performance"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Track timing of key operations"}),"\n",(0,i.jsx)(n.li,{children:"Add context about resource usage"}),"\n",(0,i.jsx)(n.li,{children:"Monitor rate limits and quotas"}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},6242:(e,n,s)=>{s.d(n,{A:()=>r});const r=s.p+"assets/images/traces-ad76742d5296a44e1f311dc2194c9ed9.png"},8453:(e,n,s)=>{s.d(n,{R:()=>a,x:()=>l});var r=s(6540);const i={},t=r.createContext(i);function a(e){const n=r.useContext(t);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),r.createElement(t.Provider,{value:n},e.children)}}}]);