"use strict";(self.webpackChunkneuraltrust_docs=self.webpackChunkneuraltrust_docs||[]).push([[6210],{79827:t=>{t.exports=JSON.parse('{"categoryGeneratedIndex":{"title":"Toxicity Detection","description":"The Toxicity Detection plugin provides content moderation capabilities by analyzing and filtering potentially harmful or inappropriate content in API requests using OpenAI\'s moderation API. It can detect various categories of toxic content including sexual content, violence, hate speech, self-harm, and illicit content.","slug":"/category/toxicity-detection","permalink":"/category/toxicity-detection","sidebar":"tutorialSidebar","navigation":{"previous":{"title":"Data Masking","permalink":"/ai-gateway/plugins/data-masking"},"next":{"title":"OpenAI Toxicity Detection","permalink":"/ai-gateway/plugins/toxicity_detection/toxicity-openai-detection"}}}}')}}]);