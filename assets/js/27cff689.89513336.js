"use strict";(self.webpackChunkneuraltrust_docs=self.webpackChunkneuraltrust_docs||[]).push([[5608],{77897:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>i,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"trustlens/key-concepts/tracing","title":"Tracing","description":"Comprehensive tracing capabilities for monitoring and debugging your LLM applications.","source":"@site/docs/trustlens/key-concepts/tracing.md","sourceDirName":"trustlens/key-concepts","slug":"/trustlens/key-concepts/tracing","permalink":"/trustlens/key-concepts/tracing","draft":false,"unlisted":false,"editUrl":"https://github.com/NeuralTrust/neuraltrust/blob/main/docs/trustlens/key-concepts/tracing.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Analytics","permalink":"/trustlens/key-concepts/analytics"},"next":{"title":"Monitors","permalink":"/trustlens/key-concepts/monitors"}}');var r=s(74848),a=s(28453);const i={sidebar_position:3},o="Tracing",c={},l=[{value:"Why Trace LLM Applications?",id:"why-trace-llm-applications",level:2},{value:"Overview",id:"overview",level:2},{value:"Basic Usage",id:"basic-usage",level:2},{value:"Event Types",id:"event-types",level:2},{value:"MESSAGE",id:"message",level:3},{value:"TOOL",id:"tool",level:3},{value:"GENERATION",id:"generation",level:3},{value:"AGENT",id:"agent",level:3},{value:"RETRIEVAL",id:"retrieval",level:3},{value:"SYSTEM",id:"system",level:3},{value:"FEEDBACK",id:"feedback",level:3},{value:"Advanced Tracing Features",id:"advanced-tracing-features",level:2},{value:"Nested Tracing",id:"nested-tracing",level:3}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"tracing",children:"Tracing"})}),"\n",(0,r.jsx)(n.p,{children:"Comprehensive tracing capabilities for monitoring and debugging your LLM applications."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Tracing",src:s(78435).A+"",width:"1110",height:"762"})}),"\n",(0,r.jsx)(n.h2,{id:"why-trace-llm-applications",children:"Why Trace LLM Applications?"}),"\n",(0,r.jsx)(n.p,{children:"LLM applications can be complex systems with many moving parts - from prompt construction and context retrieval to tool usage and response generation. When something goes wrong or behaves unexpectedly, it can be challenging to understand exactly what happened. Tracing provides:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Debugging Clarity"}),": See exactly how your LLM processed a request, what context it used, and how it arrived at its response"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Performance Insights"}),": Identify bottlenecks in your application, like slow API calls or expensive retrievals"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Quality Monitoring"}),": Track the quality of LLM outputs and user satisfaction over time"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Compliance & Auditing"}),": Maintain detailed records of all LLM interactions for compliance requirements"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Cost Optimization"}),": Understand which parts of your system are making the most LLM calls and optimize accordingly"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,r.jsx)(n.p,{children:"The tracing system captures detailed information about your LLM application's behavior and performance. This includes:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Message flows"}),": Track the complete conversation flow between users and your LLM, including intermediate steps"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Tool usage"}),": Monitor when and how your LLM uses external tools, APIs, and function calls"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Agent interactions"}),": Record agent reasoning steps, decisions, and actions taken"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Data retrievals"}),": Track RAG operations, document fetches, and context augmentation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Response generations"}),": Capture prompt construction, LLM calls, and response processing"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"System events"}),": Log infrastructure events, errors, and runtime information"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Custom events"}),": Define and track application-specific events important to your use case"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"User feedback"}),": Collect explicit ratings, implicit signals, and interaction outcomes"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"basic-usage",children:"Basic Usage"}),"\n",(0,r.jsx)(n.p,{children:"Create a trace and add events:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Initialize a trace\ntrace = client.trace(\n    conversation_id="conv_123",\n    session_id="session_123"\n)\n\n# Add a message event\nmessage = trace.message("User: What\'s the weather?")\nmessage.end("Bot: It\'s sunny!")\n'})}),"\n",(0,r.jsx)(n.h2,{id:"event-types",children:"Event Types"}),"\n",(0,r.jsx)(n.p,{children:"Each event type serves a specific purpose in tracking your LLM application's behavior:"}),"\n",(0,r.jsx)(n.h3,{id:"message",children:"MESSAGE"}),"\n",(0,r.jsx)(n.p,{children:"Root-level conversation events that capture the main interaction flow. Use these to track the overall conversation structure."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'message = trace.message("User input")\nmessage.end("Bot response")\n'})}),"\n",(0,r.jsx)(n.h3,{id:"tool",children:"TOOL"}),"\n",(0,r.jsx)(n.p,{children:"Tracks external tool and API usage. Perfect for monitoring function calls, database queries, or any external service interactions."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'tool = message.tool("Calling weather API")\ntool.end("API response received")\n'})}),"\n",(0,r.jsx)(n.h3,{id:"generation",children:"GENERATION"}),"\n",(0,r.jsx)(n.p,{children:"Captures LLM prompt construction and response generation. Use this to monitor token usage, response quality, and generation parameters."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'generation = message.generation("Generating response")\ngeneration.end("Response generated")\n'})}),"\n",(0,r.jsx)(n.h3,{id:"agent",children:"AGENT"}),"\n",(0,r.jsx)(n.p,{children:"Records agent reasoning steps and decisions. Useful for understanding how your LLM agent processes tasks and makes choices."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'agent = message.agent("Planning next action")\nagent.end("Decided to search database")\n'})}),"\n",(0,r.jsx)(n.h3,{id:"retrieval",children:"RETRIEVAL"}),"\n",(0,r.jsx)(n.p,{children:"Monitors document retrievals and RAG operations. Tracks what context was fetched and how it was used."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'retrieval = message.retrieval("Searching knowledge base")\nretrieval.end("Found 3 relevant documents")\n'})}),"\n",(0,r.jsx)(n.h3,{id:"system",children:"SYSTEM"}),"\n",(0,r.jsx)(n.p,{children:"Captures infrastructure events and runtime information. Use for monitoring system health and performance."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'system = trace.system("Initializing cache")\nsystem.end("Cache warmed up")\n'})}),"\n",(0,r.jsx)(n.h3,{id:"feedback",children:"FEEDBACK"}),"\n",(0,r.jsx)(n.p,{children:"Records user feedback and interaction outcomes. Essential for quality monitoring and improvement."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'trace.feedback(\n    feedback_tag="THUMBS_UP",\n    feedback_text="User marked response as helpful"\n)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"advanced-tracing-features",children:"Advanced Tracing Features"}),"\n",(0,r.jsx)(n.h3,{id:"nested-tracing",children:"Nested Tracing"}),"\n",(0,r.jsx)(n.p,{children:"Nested tracing is the recommended way to track complex interactions in your LLM application. It creates a hierarchical structure that makes it easy to understand the relationship between different operations:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Initialize trace with basic context\ntrace = client.trace(\n    conversation_id="conv_123",\n    metadata=Metadata(environment="production"),\n    user=User(id="user_123")\n)\n\ntry:\n    # Start main conversation trace\n    message = trace.message("User: Tell me about neural networks")\n    \n    # Track document retrieval\n    retrieval = message.retrieval("Searching documentation")\n    retrieval.end("Found 2 relevant articles")\n    \n    # Track response generation\n    generation = message.generation("Creating explanation")\n    generation.end("Generated response about neural networks")\n    \n    # Complete the conversation\n    message.end("Bot: Neural networks are...")\n\nexcept Exception as e:\n    message.end(f"Error: {str(e)}")\n'})})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},78435:(e,n,s)=>{s.d(n,{A:()=>t});const t=s.p+"assets/images/traces-ad76742d5296a44e1f311dc2194c9ed9.png"},28453:(e,n,s)=>{s.d(n,{R:()=>i,x:()=>o});var t=s(96540);const r={},a=t.createContext(r);function i(e){const n=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);