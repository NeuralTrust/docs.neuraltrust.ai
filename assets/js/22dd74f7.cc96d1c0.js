"use strict";(self.webpackChunkneuraltrust_docs=self.webpackChunkneuraltrust_docs||[]).push([[1567],{5226:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"TrustGate","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Getting Started","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Overview","href":"/ai-gateway/getting-started/introduction","docId":"ai-gateway/getting-started/introduction","unlisted":false},{"type":"category","label":"Step-by-Step Guide","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Overview","href":"/ai-gateway/getting-started/step-by-step/overview","docId":"ai-gateway/getting-started/step-by-step/overview","unlisted":false},{"type":"link","label":"Get AI Gateway","href":"/ai-gateway/getting-started/step-by-step/get-ai-gateway","docId":"ai-gateway/getting-started/step-by-step/get-ai-gateway","unlisted":false},{"type":"link","label":"Create Your First Gateway","href":"/ai-gateway/getting-started/step-by-step/first-gateway","docId":"ai-gateway/getting-started/step-by-step/first-gateway","unlisted":false},{"type":"link","label":"Configure an Upstream","href":"/ai-gateway/getting-started/step-by-step/configure-upstream","docId":"ai-gateway/getting-started/step-by-step/configure-upstream","unlisted":false},{"type":"link","label":"Configure a Service","href":"/ai-gateway/getting-started/step-by-step/add-service","docId":"ai-gateway/getting-started/step-by-step/add-service","unlisted":false},{"type":"link","label":"Create Rules","href":"/ai-gateway/getting-started/step-by-step/create-rules","docId":"ai-gateway/getting-started/step-by-step/create-rules","unlisted":false},{"type":"link","label":"Load Balancing","href":"/ai-gateway/getting-started/step-by-step/load-balancing","docId":"ai-gateway/getting-started/step-by-step/load-balancing","unlisted":false},{"type":"link","label":"Rate Limiting","href":"/ai-gateway/getting-started/step-by-step/rate-limiting","docId":"ai-gateway/getting-started/step-by-step/rate-limiting","unlisted":false}],"href":"/category/step-by-step-guide"}],"href":"/category/getting-started"},{"type":"category","label":"Key Concepts","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Gateway","href":"/ai-gateway/concepts/gateway","docId":"ai-gateway/concepts/gateway","unlisted":false},{"type":"link","label":"Services","href":"/ai-gateway/concepts/services","docId":"ai-gateway/concepts/services","unlisted":false},{"type":"link","label":"Upstreams","href":"/ai-gateway/concepts/upstreams","docId":"ai-gateway/concepts/upstreams","unlisted":false},{"type":"link","label":"Rules","href":"/ai-gateway/concepts/rules","docId":"ai-gateway/concepts/rules","unlisted":false},{"type":"link","label":"Plugins","href":"/ai-gateway/concepts/plugins","docId":"ai-gateway/concepts/plugins","unlisted":false},{"type":"link","label":"Traffic Management","href":"/ai-gateway/concepts/traffic-management","docId":"ai-gateway/concepts/traffic-management","unlisted":false},{"type":"link","label":"Consumer Groups","href":"/ai-gateway/concepts/consumer-groups","docId":"ai-gateway/concepts/consumer-groups","unlisted":false}],"href":"/category/key-concepts"},{"type":"category","label":"Guides","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"authentication","href":"/ai-gateway/guides/authentication","docId":"ai-gateway/guides/authentication","unlisted":false},{"type":"link","label":"monitoring","href":"/ai-gateway/guides/monitoring","docId":"ai-gateway/guides/monitoring","unlisted":false},{"type":"link","label":"security","href":"/ai-gateway/guides/security","docId":"ai-gateway/guides/security","unlisted":false}],"href":"/category/guides"},{"type":"category","label":"Plugins","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Rate Limiting","href":"/ai-gateway/plugins/rate-limiting","docId":"ai-gateway/plugins/rate-limiting","unlisted":false}],"href":"/category/plugins"},{"type":"category","label":"API","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Admin API (Port 8080)","href":"/ai-gateway/api/admin-api","docId":"ai-gateway/api/admin-api","unlisted":false},{"type":"link","label":"Proxy API (Port 8081)","href":"/ai-gateway/api/proxy-api","docId":"ai-gateway/api/proxy-api","unlisted":false}],"href":"/category/api"},{"type":"link","label":"Benchmark","href":"/ai-gateway/benchmark","docId":"ai-gateway/benchmark","unlisted":false},{"type":"category","label":"Deployment","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"configuration","href":"/ai-gateway/deployment/configuration","docId":"ai-gateway/deployment/configuration","unlisted":false},{"type":"link","label":"installation","href":"/ai-gateway/deployment/installation","docId":"ai-gateway/deployment/installation","unlisted":false},{"type":"link","label":"scaling","href":"/ai-gateway/deployment/scaling","docId":"ai-gateway/deployment/scaling","unlisted":false}],"href":"/category/deployment"}],"href":"/category/trustgate"},{"type":"category","label":"Red Teaming","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Getting Started","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Overview","href":"/red-teaming/getting-started/overview","docId":"red-teaming/getting-started/overview","unlisted":false},{"type":"category","label":"Step-by-Step Guide","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Overview","href":"/red-teaming/getting-started/step-by-step/overview","docId":"red-teaming/getting-started/step-by-step/overview","unlisted":false},{"type":"link","label":"Configure your LLM endpoint","href":"/red-teaming/getting-started/step-by-step/configure-llm-endpoint","docId":"red-teaming/getting-started/step-by-step/configure-llm-endpoint","unlisted":false},{"type":"link","label":"Create and run a Functional Evaluation Set from RAG","href":"/red-teaming/getting-started/step-by-step/create-functional-evaluation-set","docId":"red-teaming/getting-started/step-by-step/create-functional-evaluation-set","unlisted":false},{"type":"link","label":"Run a Custom Objective Attack","href":"/red-teaming/getting-started/step-by-step/run-custom-attack","docId":"red-teaming/getting-started/step-by-step/run-custom-attack","unlisted":false},{"type":"link","label":"Run a Compliance Scan","href":"/red-teaming/getting-started/step-by-step/run-complience-scan","docId":"red-teaming/getting-started/step-by-step/run-complience-scan","unlisted":false}],"href":"/category/step-by-step-guide-1"}],"href":"/category/getting-started-1"},{"type":"category","label":"Key Concepts","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Key Components","href":"/red-teaming/key-concepts/overview","docId":"red-teaming/key-concepts/overview","unlisted":false},{"type":"link","label":"Evaluation Sets","href":"/red-teaming/key-concepts/evaluation-sets","docId":"red-teaming/key-concepts/evaluation-sets","unlisted":false},{"type":"link","label":"Test Sets","href":"/red-teaming/key-concepts/testsets","docId":"red-teaming/key-concepts/testsets","unlisted":false},{"type":"link","label":"Knowledge Bases","href":"/red-teaming/key-concepts/knowledge-bases","docId":"red-teaming/key-concepts/knowledge-bases","unlisted":false},{"type":"link","label":"Model Scanner","href":"/red-teaming/key-concepts/scanner","docId":"red-teaming/key-concepts/scanner","unlisted":false}],"href":"/category/key-concepts-1"}],"href":"/category/red-teaming"},{"type":"category","label":"LLM Observability","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Getting Started","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Overview","href":"/observability/getting-started/overview","docId":"observability/getting-started/overview","unlisted":false},{"type":"category","label":"Step-by-Step Guide","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Overview","href":"/observability/getting-started/step-by-step/overview","docId":"observability/getting-started/step-by-step/overview","unlisted":false},{"type":"link","label":"Track your LLM","href":"/observability/getting-started/step-by-step/track-llm","docId":"observability/getting-started/step-by-step/track-llm","unlisted":false},{"type":"link","label":"Create a Custom Topic Classifier","href":"/observability/getting-started/step-by-step/create-topic-classifier","docId":"observability/getting-started/step-by-step/create-topic-classifier","unlisted":false},{"type":"link","label":"Create a Custom Monitor","href":"/observability/getting-started/step-by-step/create-custom-monitor","docId":"observability/getting-started/step-by-step/create-custom-monitor","unlisted":false}],"href":"/category/step-by-step-guide-2"}],"href":"/category/getting-started-2"},{"type":"category","label":"Key Concepts","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Analytics","href":"/observability/key-concepts/analytics","docId":"observability/key-concepts/analytics","unlisted":false},{"type":"link","label":"Tracing","href":"/observability/key-concepts/tracing","docId":"observability/key-concepts/tracing","unlisted":false},{"type":"link","label":"Monitors","href":"/observability/key-concepts/monitors","docId":"observability/key-concepts/monitors","unlisted":false}],"href":"/category/key-concepts-2"}],"href":"/category/llm-observability"},{"type":"category","label":"SDKs","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Python","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Installation","href":"/sdks/python-sdk/installation","docId":"sdks/python-sdk/installation","unlisted":false},{"type":"category","label":"API Reference","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"NeuralTrust","href":"/sdks/python-sdk/api-reference/neuraltrust-client","docId":"sdks/python-sdk/api-reference/neuraltrust-client","unlisted":false},{"type":"link","label":"_Trace","href":"/sdks/python-sdk/api-reference/trace-class","docId":"sdks/python-sdk/api-reference/trace-class","unlisted":false},{"type":"link","label":"NeuralTrustApi","href":"/sdks/python-sdk/api-reference/neuraltrust-api","docId":"sdks/python-sdk/api-reference/neuraltrust-api","unlisted":false},{"type":"link","label":"ScannerClient","href":"/sdks/python-sdk/api-reference/scanner-client","docId":"sdks/python-sdk/api-reference/scanner-client","unlisted":false},{"type":"link","label":"TestsetClient","href":"/sdks/python-sdk/api-reference/testset-client","docId":"sdks/python-sdk/api-reference/testset-client","unlisted":false},{"type":"link","label":"EvaluationSetClient","href":"/sdks/python-sdk/api-reference/evaluation-set-client","docId":"sdks/python-sdk/api-reference/evaluation-set-client","unlisted":false},{"type":"link","label":"TraceClient","href":"/sdks/python-sdk/api-reference/trace-client","docId":"sdks/python-sdk/api-reference/trace-client","unlisted":false},{"type":"link","label":"KnowledgeBaseClient","href":"/sdks/python-sdk/api-reference/knowledge-base-client","docId":"sdks/python-sdk/api-reference/knowledge-base-client","unlisted":false}],"href":"/category/api-reference"},{"type":"category","label":"Examples","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Functional Evaluation Set Generation","href":"/sdks/python-sdk/usage/functional-evaluation-set","docId":"sdks/python-sdk/usage/functional-evaluation-set","unlisted":false},{"type":"link","label":"Tracing","href":"/sdks/python-sdk/usage/tracing","docId":"sdks/python-sdk/usage/tracing","unlisted":false},{"type":"link","label":"Compliance scan","href":"/sdks/python-sdk/usage/scan","docId":"sdks/python-sdk/usage/scan","unlisted":false},{"type":"link","label":"Custom Attack","href":"/sdks/python-sdk/usage/custom-attack","docId":"sdks/python-sdk/usage/custom-attack","unlisted":false}],"href":"/category/examples"}],"href":"/category/python"}],"href":"/category/sdks"}]},"docs":{"ai-gateway/api/admin-api":{"id":"ai-gateway/api/admin-api","title":"Admin API (Port 8080)","description":"1. Create a tenant:","sidebar":"tutorialSidebar"},"ai-gateway/api/proxy-api":{"id":"ai-gateway/api/proxy-api","title":"Proxy API (Port 8081)","description":"Forward requests through the proxy::","sidebar":"tutorialSidebar"},"ai-gateway/benchmark":{"id":"ai-gateway/benchmark","title":"Benchmark","description":"The AI Gateway has been tested under high load conditions to ensure optimal performance. This guide explains how to run benchmarks and interpret the results.","sidebar":"tutorialSidebar"},"ai-gateway/concepts/consumer-groups":{"id":"ai-gateway/concepts/consumer-groups","title":"Consumer Groups","description":"A consumer group in AI Gateway allows you to organize and manage consumers (API users) collectively. This enables you to apply plugins and policies to multiple consumers at once, making it easier to manage access control and rate limiting for different types of users.","sidebar":"tutorialSidebar"},"ai-gateway/concepts/gateway":{"id":"ai-gateway/concepts/gateway","title":"Gateway","description":"A gateway in AI Gateway is a logical grouping of configurations that defines how API traffic should be managed, secured, and routed. Each gateway is identified by a unique subdomain and can be configured with its own set of plugins, services, and routing rules.","sidebar":"tutorialSidebar"},"ai-gateway/concepts/plugins":{"id":"ai-gateway/concepts/plugins","title":"Plugins","description":"Plugins are modular components that extend and customize AI Gateway\'s functionality. The plugin system follows a stage-based execution model, allowing plugins to process requests and responses at different points in the request lifecycle.","sidebar":"tutorialSidebar"},"ai-gateway/concepts/rules":{"id":"ai-gateway/concepts/rules","title":"Rules","description":"A rule in AI Gateway determines how incoming requests are matched and forwarded to services. Rules act as the traffic routing configuration that maps incoming requests to the appropriate services based on paths, methods, and other conditions.","sidebar":"tutorialSidebar"},"ai-gateway/concepts/services":{"id":"ai-gateway/concepts/services","title":"Services","description":"In AI Gateway, a service is an entity representing an external upstream API or AI model endpoint. For example, an OpenAI API endpoint, an Anthropic Claude service, or your own custom AI model service.","sidebar":"tutorialSidebar"},"ai-gateway/concepts/traffic-management":{"id":"ai-gateway/concepts/traffic-management","title":"Traffic Management","description":"The AI Gateway provides advanced traffic management capabilities to control how requests are distributed across multiple targets, enabling sophisticated load balancing, testing, and deployment strategies.","sidebar":"tutorialSidebar"},"ai-gateway/concepts/upstreams":{"id":"ai-gateway/concepts/upstreams","title":"Upstreams","description":"An upstream represents a virtual hostname that can be used to load balance incoming requests across multiple services (targets). In AI Gateway, upstreams define where and how requests are forwarded to backend AI services.","sidebar":"tutorialSidebar"},"ai-gateway/deployment/configuration":{"id":"ai-gateway/deployment/configuration","title":"configuration","description":"","sidebar":"tutorialSidebar"},"ai-gateway/deployment/installation":{"id":"ai-gateway/deployment/installation","title":"installation","description":"","sidebar":"tutorialSidebar"},"ai-gateway/deployment/scaling":{"id":"ai-gateway/deployment/scaling","title":"scaling","description":"","sidebar":"tutorialSidebar"},"ai-gateway/getting-started/introduction":{"id":"ai-gateway/getting-started/introduction","title":"Trust Gate","description":"TrustGate is a robust security and management layer for Large Language Model (LLM) interactions. It provides comprehensive protection, monitoring, and governance for AI applications while enabling organizations to safely deploy and scale their LLM-powered solutions with confidence.","sidebar":"tutorialSidebar"},"ai-gateway/getting-started/step-by-step/add-service":{"id":"ai-gateway/getting-started/step-by-step/add-service","title":"Configure a Service","description":"This guide will walk you through adding your first service in AI Gateway. A service represents your backend API or AI model endpoint that you want to expose through the gateway.","sidebar":"tutorialSidebar"},"ai-gateway/getting-started/step-by-step/configure-upstream":{"id":"ai-gateway/getting-started/step-by-step/configure-upstream","title":"Configure an Upstream","description":"This guide will walk you through configuring your first upstream in AI Gateway. An upstream defines how requests are distributed across multiple AI providers and models.","sidebar":"tutorialSidebar"},"ai-gateway/getting-started/step-by-step/create-rules":{"id":"ai-gateway/getting-started/step-by-step/create-rules","title":"Create Rules","description":"This guide will walk you through creating rules in AI Gateway. Rules determine how incoming requests are matched and routed to your services.","sidebar":"tutorialSidebar"},"ai-gateway/getting-started/step-by-step/first-gateway":{"id":"ai-gateway/getting-started/step-by-step/first-gateway","title":"Create Your First Gateway","description":"After installing AI Gateway, the next step is to create your first gateway instance. This guide will walk you through creating and configuring a basic gateway.","sidebar":"tutorialSidebar"},"ai-gateway/getting-started/step-by-step/get-ai-gateway":{"id":"ai-gateway/getting-started/step-by-step/get-ai-gateway","title":"Get AI Gateway","description":"TrustGate is available in Open Source. This guide covers the installation methods for the Open Source version.","sidebar":"tutorialSidebar"},"ai-gateway/getting-started/step-by-step/load-balancing":{"id":"ai-gateway/getting-started/step-by-step/load-balancing","title":"Load Balancing","description":"Load balancing helps distribute AI model requests across multiple instances for better performance and reliability.","sidebar":"tutorialSidebar"},"ai-gateway/getting-started/step-by-step/overview":{"id":"ai-gateway/getting-started/step-by-step/overview","title":"Overview","description":"This guide will walk you through setting up and configuring your first AI Gateway instance. By following these steps, you\'ll learn how to:","sidebar":"tutorialSidebar"},"ai-gateway/getting-started/step-by-step/rate-limiting":{"id":"ai-gateway/getting-started/step-by-step/rate-limiting","title":"Rate Limiting","description":"Rate limiting helps protect your AI models from overuse and ensures fair resource distribution among consumers.","sidebar":"tutorialSidebar"},"ai-gateway/guides/authentication":{"id":"ai-gateway/guides/authentication","title":"authentication","description":"","sidebar":"tutorialSidebar"},"ai-gateway/guides/monitoring":{"id":"ai-gateway/guides/monitoring","title":"monitoring","description":"","sidebar":"tutorialSidebar"},"ai-gateway/guides/security":{"id":"ai-gateway/guides/security","title":"security","description":"","sidebar":"tutorialSidebar"},"ai-gateway/plugins/rate-limiting":{"id":"ai-gateway/plugins/rate-limiting","title":"Rate Limiting","description":"Overview","sidebar":"tutorialSidebar"},"observability/getting-started/overview":{"id":"observability/getting-started/overview","title":"What\'s LLM Observability?","description":"LLM Observability is the practice of monitoring, tracking, and analyzing the behavior and performance of Large Language Models (LLMs) in production environments. As organizations increasingly rely on AI and LLMs for critical business operations, having robust observability becomes essential for maintaining reliability, safety, and compliance.","sidebar":"tutorialSidebar"},"observability/getting-started/step-by-step/create-custom-monitor":{"id":"observability/getting-started/step-by-step/create-custom-monitor","title":"Create a Custom Monitor","description":"Monitor Creation Interface","sidebar":"tutorialSidebar"},"observability/getting-started/step-by-step/create-topic-classifier":{"id":"observability/getting-started/step-by-step/create-topic-classifier","title":"Create a Custom Topic Classifier","description":"Custom topic classifiers help you categorize conversations based on your specific business needs.","sidebar":"tutorialSidebar"},"observability/getting-started/step-by-step/overview":{"id":"observability/getting-started/step-by-step/overview","title":"Overview","description":"This guide will walk you through setting up and configuring NeuralTrust to gather data and insights about your LLM applications. By following these steps, you\'ll learn how to:","sidebar":"tutorialSidebar"},"observability/getting-started/step-by-step/track-llm":{"id":"observability/getting-started/step-by-step/track-llm","title":"Track your LLM","description":"This guide demonstrates how to use Neural Trust\'s tracing functionality to monitor and analyze conversations in your AI application.","sidebar":"tutorialSidebar"},"observability/key-concepts/analytics":{"id":"observability/key-concepts/analytics","title":"Analytics","description":"The Analytics dashboards provides comprehensive insights into your LLM endpoint performance, usage patterns, and security metrics. This powerful observability tool helps you monitor and optimize your AI applications across multiple dimensions.","sidebar":"tutorialSidebar"},"observability/key-concepts/monitors":{"id":"observability/key-concepts/monitors","title":"Monitors","description":"Monitoring LLM applications is essential for maintaining performance, controlling costs, and ensuring quality. Through the NeuralTrust platform, you can track key metrics and receive alerts when issues arise.","sidebar":"tutorialSidebar"},"observability/key-concepts/tracing":{"id":"observability/key-concepts/tracing","title":"Tracing","description":"Comprehensive tracing capabilities for monitoring and debugging your LLM applications.","sidebar":"tutorialSidebar"},"red-teaming/getting-started/overview":{"id":"red-teaming/getting-started/overview","title":"What\'s Red Teaming for LLMs?","description":"Red teaming is a critical practice for evaluating Large Language Models (LLMs) by systematically challenging their behaviors, safety measures, and potential vulnerabilities. While traditionally associated with security testing, LLM red teaming encompasses both security assessment and functional evaluation of model capabilities.","sidebar":"tutorialSidebar"},"red-teaming/getting-started/step-by-step/configure-llm-endpoint":{"id":"red-teaming/getting-started/step-by-step/configure-llm-endpoint","title":"Configure your LLM endpoint","description":"This guide explains how to configure your LLM endpoint to invoke through NeuralTrust.","sidebar":"tutorialSidebar"},"red-teaming/getting-started/step-by-step/create-functional-evaluation-set":{"id":"red-teaming/getting-started/step-by-step/create-functional-evaluation-set","title":"Create and run a Functional Evaluation Set from RAG","description":"This guide explains how to use the NeuralTrust SDK to create and evaluate a functional evaluation set from a RAG.","sidebar":"tutorialSidebar"},"red-teaming/getting-started/step-by-step/overview":{"id":"red-teaming/getting-started/step-by-step/overview","title":"Overview","description":"This guide will walk you through setting up and configuring your first Red Teaming evaluations against your LLM\'s. By following these steps, you\'ll learn how to:","sidebar":"tutorialSidebar"},"red-teaming/getting-started/step-by-step/run-complience-scan":{"id":"red-teaming/getting-started/step-by-step/run-complience-scan","title":"Run a Compliance Scan","description":"This guide demonstrates how to use the NeuralTrust API to run compliance scans that analyze your AI system for potential vulnerabilities.","sidebar":"tutorialSidebar"},"red-teaming/getting-started/step-by-step/run-custom-attack":{"id":"red-teaming/getting-started/step-by-step/run-custom-attack","title":"Run a Custom Objective Attack","description":"This guide demonstrates how to create a custom security test using the NeuralTrust API to evaluate AI model responses against specific security objectives.","sidebar":"tutorialSidebar"},"red-teaming/key-concepts/evaluation-sets":{"id":"red-teaming/key-concepts/evaluation-sets","title":"Evaluation Sets","description":"Evaluation Sets are a core feature of the NeuralTrust platform that allow you to systematically test and evaluate AI models. They provide a structured way to organize and automate collections of tests to assess model performance, safety, and compliance.","sidebar":"tutorialSidebar"},"red-teaming/key-concepts/knowledge-bases":{"id":"red-teaming/key-concepts/knowledge-bases","title":"Knowledge Bases","description":"Knowledge Bases are a powerful feature of the NeuralTrust platform that allow you to create and manage specialized knowledge repositories for AI model testing and evaluation. They provide a structured way to organize domain-specific information that can be used to enhance your model testing capabilities.","sidebar":"tutorialSidebar"},"red-teaming/key-concepts/overview":{"id":"red-teaming/key-concepts/overview","title":"Key Components","description":"NeuralTrust defines the following components to support the above use cases:","sidebar":"tutorialSidebar"},"red-teaming/key-concepts/scanner":{"id":"red-teaming/key-concepts/scanner","title":"Model Scanner","description":"The Model Scanner is a crucial tool for evaluating and ensuring the safety and compliance of Large Language Models (LLMs). As LLMs become increasingly integrated into production systems, it\'s essential to proactively identify and mitigate potential risks related to harmful, biased, or malicious content generation.","sidebar":"tutorialSidebar"},"red-teaming/key-concepts/testsets":{"id":"red-teaming/key-concepts/testsets","title":"Test Sets","description":"Test Sets are a fundamental component of the NeuralTrust platform that enable you to create and manage collections of test cases for AI model evaluation. Each test set contains multiple query-response pairs, where each pair consists of:","sidebar":"tutorialSidebar"},"sdks/python-sdk/api-reference/evaluation-set-client":{"id":"sdks/python-sdk/api-reference/evaluation-set-client","title":"EvaluationSetClient","description":"Client for managing evaluation sets through the NeuralTrust API. This class provides methods for creating, retrieving, updating, deleting, and running evaluation sets.","sidebar":"tutorialSidebar"},"sdks/python-sdk/api-reference/knowledge-base-client":{"id":"sdks/python-sdk/api-reference/knowledge-base-client","title":"KnowledgeBaseClient","description":"Client for interacting with NeuralTrust Knowledge Base API endpoints. This class provides methods for creating, retrieving, and deleting knowledge bases.","sidebar":"tutorialSidebar"},"sdks/python-sdk/api-reference/neuraltrust-api":{"id":"sdks/python-sdk/api-reference/neuraltrust-api","title":"NeuralTrustApi","description":"Main client for interacting with the NeuralTrust API. This class provides synchronous access to various NeuralTrust services, handling authentication and request configuration.","sidebar":"tutorialSidebar"},"sdks/python-sdk/api-reference/neuraltrust-client":{"id":"sdks/python-sdk/api-reference/neuraltrust-client","title":"NeuralTrust","description":"Main client for interacting with the NeuralTrust API. This class provides the main interface for interacting with NeuralTrust services, handling authentication and providing access to various API endpoints.","sidebar":"tutorialSidebar"},"sdks/python-sdk/api-reference/scanner-client":{"id":"sdks/python-sdk/api-reference/scanner-client","title":"ScannerClient","description":"Client for interacting with NeuralTrust\'s scanning and red teaming capabilities. This class provides methods for performing security scans and custom red teaming attacks on LLM systems.","sidebar":"tutorialSidebar"},"sdks/python-sdk/api-reference/testset-client":{"id":"sdks/python-sdk/api-reference/testset-client","title":"TestsetClient","description":"Client for managing testsets through the NeuralTrust API. This class provides methods for creating, retrieving, listing, and deleting testsets.","sidebar":"tutorialSidebar"},"sdks/python-sdk/api-reference/trace-class":{"id":"sdks/python-sdk/api-reference/trace-class","title":"_Trace","description":"Internal class for creating and managing traces in the NeuralTrust system. This class captures details about interactions or events, including metadata, timing information, and content.","sidebar":"tutorialSidebar"},"sdks/python-sdk/api-reference/trace-client":{"id":"sdks/python-sdk/api-reference/trace-client","title":"TraceClient","description":"Client for interacting with the NeuralTrust Trace API. This class provides functionality for creating and managing traces of interactions and events in the NeuralTrust system.","sidebar":"tutorialSidebar"},"sdks/python-sdk/installation":{"id":"sdks/python-sdk/installation","title":"Installation","description":"You can install the Neural Trust Python SDK using pip or other package managers with access to PyPI:","sidebar":"tutorialSidebar"},"sdks/python-sdk/usage/custom-attack":{"id":"sdks/python-sdk/usage/custom-attack","title":"Custom Attack","description":"This guide demonstrates how to create a custom security test using the NeuralTrust API to evaluate AI model responses against specific security objectives.","sidebar":"tutorialSidebar"},"sdks/python-sdk/usage/functional-evaluation-set":{"id":"sdks/python-sdk/usage/functional-evaluation-set","title":"Functional Evaluation Set Generation","description":"This guide explains how to use the NeuralTrust SDK to create and evaluate test sets for conversational AI applications.","sidebar":"tutorialSidebar"},"sdks/python-sdk/usage/scan":{"id":"sdks/python-sdk/usage/scan","title":"Compliance scan","description":"This guide demonstrates how to use the Neural Trust scanning capabilities to analyze your AI system for potential vulnerabilities.","sidebar":"tutorialSidebar"},"sdks/python-sdk/usage/tracing":{"id":"sdks/python-sdk/usage/tracing","title":"Tracing","description":"This guide demonstrates how to use Neural Trust\'s tracing functionality to monitor and analyze conversations in your AI application.","sidebar":"tutorialSidebar"}}}}')}}]);